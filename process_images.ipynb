{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(folder_path):\n",
    "    images = []\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        if img_name == '.DS_Store':\n",
    "            continue\n",
    "        img = read_img(img_name)\n",
    "\n",
    "        if img.shape[1] > img.shape[0]:\n",
    "            img = rotate_image(img)\n",
    "\n",
    "        images.append(img)\n",
    "        \n",
    "    return images\n",
    "\n",
    "def read_img(img_name):\n",
    "   return cv2.imread(f'images/{img_name}')\n",
    "\n",
    "def rotate_image(img):\n",
    "    return cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images = read_images('images')\n",
    "processed_images = original_images.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_images(images):\n",
    "    for idx, img in enumerate(images):\n",
    "        y, h = 0, 3050  # upper starting point, shift \n",
    "        x, w = 800, 2250  # lefter starting point, shift\n",
    "\n",
    "        images[idx] = img[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_images(original_images)\n",
    "crop_images(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_channels(images):\n",
    "    for idx, img in enumerate(images):\n",
    "        img_hsv = extract_HSV_channel(img)\n",
    "        images[idx] = extract_H_channel(img_hsv)\n",
    "\n",
    "def extract_HSV_channel(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "def extract_H_channel(img_hsv):\n",
    "    return img_hsv[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_channels(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_plusplus(img, num_clusters=3): \n",
    "    pixel_values = np.float32(img.flatten())\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    _, labels, centers = cv2.kmeans(pixel_values, num_clusters, None, criteria, 10, cv2.KMEANS_PP_CENTERS)\n",
    "    centers = np.uint8(centers)\n",
    "    labels_reshaped = labels.reshape(img.shape)\n",
    "    return labels_reshaped\n",
    "\n",
    "def second_largest_cluster_mask(labels_reshaped, num_clusters):\n",
    "    masks = [cv2.inRange(labels_reshaped, cluster_id, cluster_id) for cluster_id in range(num_clusters)]\n",
    "    sizes = [cv2.countNonZero(mask) for mask in masks]\n",
    "    second_largest_cluster_mask = masks[sorted(zip(sizes, range(num_clusters)), reverse=True)[1][1]]\n",
    "\n",
    "    return second_largest_cluster_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_component_mask(mask):\n",
    "        mask = np.uint8(mask)\n",
    "        _, components = cv2.connectedComponents(mask, connectivity=8)\n",
    "        return np.uint8(components == np.argmax(np.bincount(components.flat)[1:]) + 1) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(img, mask):\n",
    "    return cv2.bitwise_and(img, img, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr_to_gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_to_bgr(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_threshhold(gray_img):\n",
    "    _, binary_img = cv2.threshold(gray_img, 1, 255, cv2.THRESH_BINARY)\n",
    "    return binary_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_blur(stem_region, kernel_size=99):\n",
    "    return cv2.medianBlur(stem_region, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_stem(masked_img, stop_distance=70):\n",
    "    binary_img = binary_threshhold(masked_img)  # changed this line\n",
    "    start_row = None\n",
    "    end_row = None\n",
    "\n",
    "    for row in range(binary_img.shape[0]):\n",
    "        current_row = binary_img[row, :]\n",
    "        non_zero_indices = np.nonzero(current_row)[0]\n",
    "    \n",
    "        if non_zero_indices.size > 0:\n",
    "            if start_row is None:\n",
    "                start_row = row\n",
    "            \n",
    "            pixel_distance = np.max(non_zero_indices) - np.min(non_zero_indices)\n",
    "            \n",
    "            if pixel_distance > stop_distance:\n",
    "                end_row = row\n",
    "                break\n",
    "\n",
    "    if (start_row is not None and end_row is not None and start_row < end_row):\n",
    "        stem_region = masked_img[start_row:end_row, :]  # changed this line\n",
    "        blurred_stem = median_blur(stem_region)\n",
    "\n",
    "        return np.vstack((masked_img[:start_row, :], blurred_stem, masked_img[end_row:, :]))  # changed this line\n",
    "    else:\n",
    "        return masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_clusters in range(2, 6):  \n",
    "    DIR = 'processed_images'\n",
    "    os.makedirs(DIR, exist_ok=True)\n",
    "\n",
    "    for idx, img in enumerate(processed_images):\n",
    "        labels_reshaped = kmeans_plusplus(img, num_clusters)\n",
    "        slcm = second_largest_cluster_mask(labels_reshaped, num_clusters)\n",
    "        lcm = largest_component_mask(slcm)\n",
    "        gray_original = bgr_to_gray(original_images[idx])\n",
    "        masked_original = apply_mask(gray_original, lcm)\n",
    "        stem_cutted_gray = cut_stem(masked_original)\n",
    "        stem_cutted_mask = binary_threshhold(stem_cutted_gray)\n",
    "        stem_cutted = apply_mask(original_images[idx], stem_cutted_mask)\n",
    "\n",
    "        filename = f'{DIR}/img{idx}_{num_clusters}clusters.png'\n",
    "        cv2.imwrite(filename, stem_cutted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf_segmentation_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
