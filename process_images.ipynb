{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 4\n",
    "ATTEMPTS = 20 # trade off time vs stability of clustering results\n",
    "KERNEL_SIZE = 55\n",
    "STOP_DIST = 66\n",
    "DIR = 'processed_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate images upside-down manually before reading in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(folder_path):\n",
    "    images = []\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        if img_name == '.DS_Store':\n",
    "            continue\n",
    "        img = read_img(img_name)\n",
    "        images.append(img)\n",
    "        \n",
    "    return images\n",
    "\n",
    "def read_img(img_name):\n",
    "   return cv2.imread(f'images/{img_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images = read_images('images')\n",
    "processed_images = original_images.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def crop_images(images):\n",
    "    for idx, img in enumerate(images):\n",
    "        y, h = 0, 3050  # upper starting point, shift \n",
    "        x, w = 800, 2250  # lefter starting point, shift\n",
    "\n",
    "        images[idx] = img[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_images(images):\n",
    "    for idx, img in enumerate(images):\n",
    "        y, h = 0, 2000  # upper starting point, lower ending point\n",
    "        x, w = 400, 1200  # lefter starting point, righter ending point\n",
    "\n",
    "        images[idx] = img[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_images(original_images)\n",
    "crop_images(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_channels(images):\n",
    "    for idx, img in enumerate(images):\n",
    "        img_hsv = extract_HSV_channel(img)\n",
    "        images[idx] = extract_H_channel(img_hsv)\n",
    "\n",
    "def extract_HSV_channel(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "def extract_H_channel(img_hsv):\n",
    "    return img_hsv[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_channels(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_mask(img, num_clusters):\n",
    "    labels_reshaped = kmeans_plusplus(img, num_clusters)\n",
    "    return second_largest_cluster_mask(labels_reshaped, num_clusters)\n",
    "\n",
    "def kmeans_plusplus(img, num_clusters): \n",
    "    pixel_values = np.float32(img.flatten())\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    _, labels, centers = cv2.kmeans(pixel_values, num_clusters, None, criteria, ATTEMPTS, cv2.KMEANS_PP_CENTERS)\n",
    "    # _, labels, centers = cv2.kmeans(pixel_values, num_clusters, None, criteria, CLUSTERING_REPEATS, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    centers = np.uint8(centers)\n",
    "    labels_reshaped = labels.reshape(img.shape)\n",
    "    return labels_reshaped\n",
    "\n",
    "def second_largest_cluster_mask(labels_reshaped, num_clusters):\n",
    "    masks = [cv2.inRange(labels_reshaped, cluster_id, cluster_id) for cluster_id in range(num_clusters)]\n",
    "    sizes = [cv2.countNonZero(mask) for mask in masks]\n",
    "    second_largest_cluster_mask = masks[sorted(zip(sizes, range(num_clusters)), reverse=True)[1][1]]\n",
    "\n",
    "    return second_largest_cluster_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def largest_component_mask(mask):\n",
    "        mask = np.uint8(mask)\n",
    "        _, components = cv2.connectedComponents(mask, connectivity=8)\n",
    "        return np.uint8(components == np.argmax(np.bincount(components.flat)[1:]) + 1) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_component_mask(mask):\n",
    "    mask = np.uint8(mask)\n",
    "    num_labels, labels = cv2.connectedComponents(mask, connectivity=8)\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "    print(\"Number of unique labels:\", num_labels) # prints the number of unique labels\n",
    "    print(\"Counts of each label:\", dict(zip(unique, counts))) # prints the counts of each label\n",
    "\n",
    "    if num_labels <= 1:\n",
    "        print(\"No components found in mask!\")\n",
    "        return mask # return the original mask if no components were found\n",
    "    \n",
    "    largest_component = np.argmax(counts[1:]) + 1\n",
    "    largest_mask = np.uint8(labels == largest_component) * 255\n",
    "    return largest_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(img, mask):\n",
    "    return cv2.bitwise_and(img, img, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_stem(masked_img, stop_distance, kernel_size):\n",
    "    binary_img = gray_to_binary(masked_img)  # changed this line\n",
    "    start_row = None\n",
    "    end_row = None\n",
    "\n",
    "    for row in range(binary_img.shape[0]):\n",
    "        current_row = binary_img[row, :]\n",
    "        non_zero_indices = np.nonzero(current_row)[0]\n",
    "    \n",
    "        if non_zero_indices.size > 0:\n",
    "            if start_row is None:\n",
    "                start_row = row\n",
    "            \n",
    "            pixel_distance = np.max(non_zero_indices) - np.min(non_zero_indices)\n",
    "            \n",
    "            if pixel_distance > stop_distance:\n",
    "                end_row = row\n",
    "                break\n",
    "\n",
    "    if (start_row is not None and end_row is not None and start_row < end_row) or start_row != 0:\n",
    "        stem_region = masked_img[start_row:end_row, :]  # changed this line\n",
    "        blurred_stem = median_blur(stem_region, kernel_size)\n",
    "\n",
    "        return np.vstack((masked_img[:start_row, :], blurred_stem, masked_img[end_row:, :]))  # changed this line\n",
    "    else:\n",
    "        print(\"Hi\")\n",
    "        return masked_img\n",
    "    \n",
    "def median_blur(stem_region, kernel_size):\n",
    "    return cv2.medianBlur(stem_region, kernel_size)\n",
    "\n",
    "def gray_to_binary(img):\n",
    "    gray_img = rgb_to_gray(img)\n",
    "    _, binary_img = cv2.threshold(gray_img, 1, 255, cv2.THRESH_BINARY)\n",
    "    return binary_img\n",
    "\n",
    "def rgb_to_gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m os\u001b[39m.\u001b[39mmakedirs(DIR, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m idx, img \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(processed_images):\n\u001b[0;32m----> 5\u001b[0m     cm \u001b[39m=\u001b[39m clustering_mask(processed_images[idx], NUM_CLUSTERS)\n\u001b[1;32m      6\u001b[0m     lcm \u001b[39m=\u001b[39m largest_component_mask(cm)\n\u001b[1;32m      7\u001b[0m     segmented \u001b[39m=\u001b[39m apply_mask(original_images[idx], lcm)\n",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m, in \u001b[0;36mclustering_mask\u001b[0;34m(img, num_clusters)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclustering_mask\u001b[39m(img, num_clusters):\n\u001b[0;32m----> 2\u001b[0m     labels_reshaped \u001b[39m=\u001b[39m kmeans_plusplus(img, num_clusters)\n\u001b[1;32m      3\u001b[0m     \u001b[39mreturn\u001b[39;00m second_largest_cluster_mask(labels_reshaped, num_clusters)\n",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m, in \u001b[0;36mkmeans_plusplus\u001b[0;34m(img, num_clusters)\u001b[0m\n\u001b[1;32m      6\u001b[0m pixel_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32(img\u001b[39m.\u001b[39mflatten())\n\u001b[1;32m      7\u001b[0m criteria \u001b[39m=\u001b[39m (cv2\u001b[39m.\u001b[39mTERM_CRITERIA_EPS \u001b[39m+\u001b[39m cv2\u001b[39m.\u001b[39mTERM_CRITERIA_MAX_ITER, \u001b[39m100\u001b[39m, \u001b[39m0.2\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m _, labels, centers \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mkmeans(pixel_values, num_clusters, \u001b[39mNone\u001b[39;49;00m, criteria, ATTEMPTS, cv2\u001b[39m.\u001b[39;49mKMEANS_PP_CENTERS)\n\u001b[1;32m      9\u001b[0m \u001b[39m# _, labels, centers = cv2.kmeans(pixel_values, num_clusters, None, criteria, CLUSTERING_REPEATS, cv2.KMEANS_RANDOM_CENTERS)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m centers \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39muint8(centers)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for num_clusters in range(2, NUM_CLUSTERS + 1):  \n",
    "    os.makedirs(DIR, exist_ok=True)\n",
    "\n",
    "    for idx, img in enumerate(processed_images):\n",
    "        cm = clustering_mask(processed_images[idx], NUM_CLUSTERS)\n",
    "        lcm = largest_component_mask(cm)\n",
    "        segmented = apply_mask(original_images[idx], lcm)\n",
    "\n",
    "        smoothed = cut_stem(segmented, STOP_DIST, KERNEL_SIZE)\n",
    "\n",
    "        smoothed = np.where(smoothed == 0, 255, smoothed)\n",
    "        # _, smoothed = cv2.threshold(smoothed, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        filename = f'{DIR}/img{idx}_{num_clusters}clusters.png'\n",
    "        cv2.imwrite(filename, smoothed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, smoothed = cv2.threshold(smoothed, 1, 255, cv2.THRESH_BINARY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf_segmentation_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
